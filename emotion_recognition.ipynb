{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMa5i7v8jvutgpCpWEb6VXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safal-tyagi/emotions-recognition/blob/master/emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lu_hGM3tlj7",
        "colab_type": "code",
        "outputId": "f0348a6c-764a-4813-8e8d-35a26e102e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# load data set from Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyKIIuEvu6lu",
        "colab_type": "code",
        "outputId": "0169fa4a-d156-43e9-a177-4350559f6972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "posts = pd.read_json(\"/gdrive/My Drive/nlp_train.json\", orient='index')\n",
        "posts = posts[['body', 'emotion']]\n",
        "print(posts.head(10))\n",
        "print(posts.count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                      body                                            emotion\n",
            "fkrr36o  He was answering a question about the criticis...  {'anger': True, 'anticipation': False, 'disgus...\n",
            "fjyfp0o  I'm going to start today's discussion thread w...  {'anger': True, 'anticipation': True, 'disgust...\n",
            "fibm0x7  By announcing the 395 self-quarantined, it pai...  {'anger': True, 'anticipation': True, 'disgust...\n",
            "fj9b4oj  Likewise, sorry if I offended you. I’m not act...  {'anger': True, 'anticipation': False, 'disgus...\n",
            "fk04ri5  People infected by experience high fever, coug...  {'anger': False, 'anticipation': False, 'disgu...\n",
            "flaz17r  &gt;At Philips, major unrest has been caused b...  {'anger': False, 'anticipation': True, 'disgus...\n",
            "fk3nb9r  I'm not worried about COVID-19 for the same re...  {'anger': False, 'anticipation': True, 'disgus...\n",
            "fjjwfqp  **32 donation stations across the country**\\n\\...  {'anger': False, 'anticipation': False, 'disgu...\n",
            "fhyzjbr  That's great. Unfortunately that is ***one*** ...  {'anger': True, 'anticipation': False, 'disgus...\n",
            "fkvtdbc  &gt; # Columbariums adopt safety measures for ...  {'anger': False, 'anticipation': True, 'disgus...\n",
            "body       1493\n",
            "emotion    1493\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7OP35OeVUwl",
        "colab_type": "code",
        "outputId": "cde54e84-1a95-4291-debc-395a5d1eb802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# split train test validation data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(posts, test_size=0.2)\n",
        "train, valid = train_test_split(train, test_size=0.2)\n",
        "\n",
        "print(len(train))\n",
        "print(len(test))\n",
        "print(len(valid))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "955\n",
            "299\n",
            "239\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8NdB-R5w-67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize text\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(lower=True)\n",
        "tokenizer.fit_on_texts(posts.body.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0IK345SVE4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save tokenized content\n",
        "import pickle\n",
        "file = open(\"/gdrive/My Drive/tokenizer.pickle\", 'wb')\n",
        "pickle.dump(tokenizer, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhM43tYaMa3C",
        "colab_type": "code",
        "outputId": "610ea3fc-e585-4ebd-9ac9-8d0fc1896220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# max token length for padding\n",
        "posts_seq = [text.split() for text in posts.body]\n",
        "tk_posts = tokenizer.texts_to_sequences(posts_seq)\n",
        "print(len(tk_posts))\n",
        "print(np.max(np.max(tk_posts)))\n",
        "\n",
        "# tokenize data\n",
        "train_seq = [text.split() for text in train.body]\n",
        "test_seq = [text.split() for text in test.body]\n",
        "valid_seq = [text.split() for text in valid.body]\n",
        "\n",
        "# convert seq\n",
        "tk_train = tokenizer.texts_to_sequences(train_seq)\n",
        "tk_test = tokenizer.texts_to_sequences(test_seq)\n",
        "tk_valid = tokenizer.texts_to_sequences(valid_seq)\n",
        "\n",
        "# pad with max len\n",
        "x_train = pad_sequences(tk_train, maxlen=500, padding='post')\n",
        "x_test = pad_sequences(tk_test, maxlen=500, padding='post')\n",
        "x_valid = pad_sequences(tk_valid, maxlen=500, padding='post')\n",
        "# sample print\n",
        "print(np.shape(x_train))\n",
        "print(x_train[0:2])\n",
        "print(x_test[0:2])\n",
        "print(x_valid[0:2])\n",
        "\n",
        "# emotion labels to binary\n",
        "y_train = [[np.multiply(val, 1) for val in emotion.values()] for emotion in train.emotion]\n",
        "y_test = [[np.multiply(val, 1) for val in list(emotion.values())] for emotion in test.emotion]\n",
        "y_valid = [[np.multiply(val, 1) for val in list(emotion.values())] for emotion in valid.emotion]\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_valid = np.array(y_valid)\n",
        "#sample print\n",
        "print(np.shape(y_train))\n",
        "print(y_train[0:2])\n",
        "print(y_test[0:2])\n",
        "print(y_valid[0:2])"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1493\n",
            "34189\n",
            "(955, 500)\n",
            "[[  181    14  1579    23    16   372     8    30     7  3242     2   647\n",
            "   1249  6973     8    16    52  3023  2307    11  9882 18520  1445     4\n",
            "     18    43   294   121     1    74    62   471     7     2   515   115\n",
            "     66    20   122    20    72   361   584    68    73    13   568 18279\n",
            "   4727     3   855  3807     3   202    32    12   270   110   397   400\n",
            "    585 33729   173    20  2155  9882     3 18520  1588  3745     3 18521\n",
            "      2   382    12     3  1467  2338  4988     7    71  1579    39     8\n",
            "     12    71   471     2 11223  4988  5838  1445    72     7    12    16\n",
            "      5    96   161   264    39   182   103  1436  3993     6   138    15\n",
            "     35     7  5151    70    23    11  1419  1655    71    57    10    67\n",
            "      1    60   761     2  1909   189   206     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 1811   294    26     1   953  1228     8     1  1505  1228  2773    19\n",
            "     84 25977   423   121     1    72    18  1095   784   142     1    79\n",
            "      2   294     1 16691   738     7    41   738 10572   863  1481   208\n",
            "      8    16  2343 16692    36 11616     3    36    74  2208     4  1162\n",
            "    200    26    45  3799     1   738  1113  4136    20     5   751 10573\n",
            "      9   543   192    14     5   534  4143     1   738  1113  4136    20\n",
            "      5   751 10573     9   543   192    18  1246     1   354     9   129\n",
            "      4     1   190    46    18   784   618     1   673    67    23    16\n",
            "    100    40    84  3335     1   313     8    23 25978    20     5   751\n",
            "  10573     9   543   192    23 16693  2343 16692    36 11616     3    36\n",
            "     74  2208     4  1162   200    26    45  3799   241  1162    80   475\n",
            "     57    18   133    10    63    17     9     1    30     2    83   468\n",
            "      6     1   190     8   261    16    10   188   312   158    73  1034\n",
            "    994  5142     1  1768    40    73     3    24     1    30    43   142\n",
            "    129   205     2   430   197    39    80   100    28    57    18   133\n",
            "     16    52   135     3    16   135   100   324     8    25   261   101\n",
            "     42    39   162  5179     3  9109   118    19   294    56    23    16\n",
            "      5  3037     4  1811   983   172     6   129     3    32    23   261\n",
            "     16     5   214     4   380    60    37    98    12    31  9512  3733\n",
            "      8    12    27    24  2900    17  1624     2  2802    37    50    31\n",
            "     17  4105    40    60     6   259  2834     1   448    34  1288     2\n",
            "    928   122    39     1   126    63    17    40   359    79  2693   809\n",
            "     41   556    26   278   294    26     1   227     3   142   375  2840\n",
            "      2   133    42     1  3263     4  1929  1640     6     1   227  2693\n",
            "     44     8 25980    60  4215     2  7040   954    22     1  1111    18\n",
            "   1030     1  5469 25981     6   662   179  8740     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "[[    2   418   811  5322    11    84   283     6     1   852    99  2645\n",
            "      5   605  2668   811   251    97  4329     6   551   590    29     2\n",
            "    391     5    99  9463   148 10294    20    41     1   605    71  1341\n",
            "    811  5322   184   953  8791     4     1   106   611 24189 24190    11\n",
            "    348     2 14195    41 24191   331     3   642  9886     1    54    75\n",
            "    198   434     8  5322    43   183   484   831  2074     3  4946   291\n",
            "   5171     3    11   583     2  8713    14  5322     6  1674   291   542\n",
            "      2    13     1    74     1    99    34 15983  1347   658  2447     2\n",
            "   5975     3 24192  3202 24193   808     2  2412     3  4635     6   498\n",
            "   1106   648   498  1609 15984     2  5322    34    52   430   108     1\n",
            "    352     1   134  1053 24194 15981  2940     6     1   298    26     1\n",
            "    504     4     1    30 24195   918   116   281     6  1408  3507    22\n",
            "      1   106    20     4   326   347     2     5   315    99    92    71\n",
            "   2185 13953     4   251   116  1132     3    40    70 10394     4    24\n",
            "     13   291  4013   146   331  4760     8     1   875  1751   103  1003\n",
            "   3110    36  3507    22     3     6   454     2   147   311    36   875\n",
            "    110     2     1   107    25    16   901     2  1450  3507  1413   241\n",
            "    256    14     1  1053    44  5602     1  3316  3019  1251     9 24198\n",
            "      1  2130  1523   132  1846     6  1984   124     2  5516     1 15986\n",
            "      4     1  1053  2012    34    44    50    11  5220  1090   174   875\n",
            "   2714    52  8363     2     1   173    20  3507     4   202     8    11\n",
            "  24199     9   146    13   326   346   198    22     1   734  1053  2012\n",
            "     64 12403     9 24200  3507     9     1  5747    41  5214    22     1\n",
            "     15  1084     1   105    79     1  1053  2012     4    48    34    58\n",
            "      2  4799     9 12339   701   213     5    69    41  7985  4636 10859\n",
            "    779     6  3239     3   981     1    99  6101     1  1053  2012    20\n",
            "      1  3423     9  1438  3507     3  1941     5   370    22  8743   470\n",
            "      6  1716  1607     8     4  2751  3507    64 15987  2147   121    99\n",
            "  15411    20 24203   722   889     1 12404     4   667 12402   229    17\n",
            "    174    75 24204    11  7516     2   147  6213  8998     2     1    30\n",
            "      4     1   281 10391    37     1   931     3  6587  2777     9   281\n",
            "      7   115     2 24206  1766   173    20     1   746     9   137   200\n",
            "      3     1   111    51   736   162   281     7  9573     9   337     1\n",
            "    281 10391    37     1  6088  3886  2441    31  3608  2425   337  1989\n",
            "      7  5211     2   154     8     3  3142    11  7857   352     3   875\n",
            "      2   183    97   799    37     1  1106  3340     1  3009  1095   430\n",
            "      8     1    99     3     1  3934   681   128   113  6465     2  6416\n",
            "   1079     2  4675     1  2848  2708  3316  2058     3   484     1   958\n",
            "      4  6884  5322    11   226    22 24210   294    26     1  1053  2012\n",
            "      6    24     6 12405  3507     2    48     7 24213    75     4   112\n",
            "    211     2     1    30   290    13     5   231 15988     6     1   167\n",
            "   4419     8 24214   112  1211   211     2     1]\n",
            " [   12   113  3296     6     5   748  2145     6     5  1476  1976     3\n",
            "    166   180    27   150 29299    70    12    27  3297    25    16     5\n",
            "    501  9095     2   191  9016     6     2   287     3   189    54     4\n",
            "     86  1466     3    36   109    11   966     4     7  2091  1264     7\n",
            "   1328     1   263 15412 29301    12    43   755     2    83  7582    13\n",
            "    148  6435    66     2     1  1827    14    62     5   243   272     3\n",
            "      5   364   272    11  2918    66    26    62     3     1   364   272\n",
            "     18  1291  1375    68    67     4     1    12    65  8421     3     9\n",
            "      1    79    12    23   182   816     3    39   182    19    12   505\n",
            "     82    14     5  2147   306     6     5    93   572     4   313    19\n",
            "    262     7   816     3    75    11   817    75    11    75   229    17\n",
            "    509    14  3162     3    91    23   259    83  5581     3     5  6200\n",
            "   4826 29302    45     1   364   272    12   952    50    11   824     3\n",
            "   2914    66   557     6     9   750     5   512   430     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "[[  873     1  2779    35     2  7585    66     4   200    67    46   170\n",
            "     19 10414     1   729     9     5 10678    80    43    18   505    78\n",
            "      8   525    31  1033    55  1652     6     1   211     2    15    10\n",
            "    564     2  5677    27    41  2526   389    37  1819   836   410     5\n",
            "  29761   427    13    51    12    27  2021     4    25    58   129  3651\n",
            "     14     1   126     4   533  5677     6  3580    58     1   105  1692\n",
            "   1034    41   533   122    40   857    70     1    12  1545     4     1\n",
            "  29762  4000     4   212  1256    14   187     3   478     3  1545     1\n",
            "  11578  1652     8   109   198  1033     6   533    25   372    36    74\n",
            "   1031     3     1   244     1    74  3035    27     6    25    58    41\n",
            "    140     4   647     6     5 29763   392    62    51   198   564     2\n",
            "     25   683  2904    51     1   896    27    10    27   103   126    37\n",
            "      1   187     4 11987   170    19   772     9  1674     5 10678    24\n",
            "      1   212   564   223     5     3    12  1224     5   106    51   275\n",
            "      9   364   124     2   618     5 10678     3    25  3122     1     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  182   320  2115     4    28   321     8    15     7    19     5   407\n",
            "    513    67   119  1825    40    28    29    67   191    58     5   458\n",
            "    532   238    39   153    11    75    25   123  2047    80   857     5\n",
            "    137     7    37  3450    10     2   232    32    10     7  2954     4\n",
            "   1617    92   388   850     3  5384    39   119  1825    40    28    67\n",
            "     10  3215    40    32    15  1097    20   122    20     1   119   220\n",
            "     15    63   905     1   167    32    19    40    28    25    57    19\n",
            "     16     5   337     9    15    25    57     9     1   119    25    57\n",
            "     19    16     5  6868   342     8   747   499     1  1398     9   119\n",
            "     25    16   990   380     2   113    50     7     5   466   174     1\n",
            "    212     3    38    11   256    15   475     2   828    15   556  1483\n",
            "      2    53    23   164     3    19    75  1629  5624 11959     8   978\n",
            "      2   412  6908    37  1021   262    55   407   513   119  1825    37\n",
            "      8    18   123   125     5  4837    69   115  4837 11960    14 11961\n",
            "     67   627     4    28   366     6  1395     3  1655    56     2   154\n",
            "    109  1291   164    15     7    19     5   407   513     2     1   292\n",
            "    637    38   179  3008    45  1866   840    39    69    12  1233   109\n",
            "  28769   820    42    80    92    19     5   407    10    65 10032   421\n",
            "      8    18   800    16     1   212    13   358     1   543    51  2160\n",
            "    275  1069     4     1   111    51   736  1224     1   140     5 10033\n",
            "     51   275     4   543 11962 11963   182    19   321    15     7    79\n",
            "      2   279    19  2300   184   102  5230    24   909    65    17   804\n",
            "      3   397  6536   155   487  1362     3    75   534   581  1001     1\n",
            "    651    12   372    13   911    69    12  6552     9  1362  1544    22\n",
            "     39    12  7053    92   419     2    36     3     7    19   144    92\n",
            "     71   286     1   413   911  3849    42    30   184    39    12   952\n",
            "     92    32    19    65   684   212     3    38   854     9     1    68\n",
            "      2  1094   545    15   729    31    71   818     1   378     4   552\n",
            "    196    92   119  1589     6   100  1172     4     1   111     3    39\n",
            "   2591    15    31    71   183   788   571     8    63    16    52  1020\n",
            "      2     1  1487  1829     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n",
            "(955, 12)\n",
            "[[0 1 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 1 0 0 1 0 0 0 0]]\n",
            "[[0 1 0 1 0 0 1 1 0 0 1 0]\n",
            " [1 0 1 0 0 0 1 1 1 0 0 0]]\n",
            "[[0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [1 1 1 1 0 1 1 0 0 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaoBJX6hZXtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSD4ZetPZmk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f9c7a4e-6f10-4fd8-8fea-400d8d39858c"
      },
      "source": [
        "input_dim = len(tokenizer.word_index) + 1\n",
        "# words = tokenizer.word_index.keys()\n",
        "# word_count = len(words)\n",
        "print(input_dim)\n",
        "model = Sequential([\n",
        "    Embedding(input_dim = input_dim, output_dim = 256, mask_zero=True),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(12)\n",
        "])"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGr9xcYaZuEb",
        "colab_type": "code",
        "outputId": "37475da9-4ba2-44df-fe7f-6c5bce73a0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.compile(loss=CategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_33 (Embedding)     (None, None, 256)         8763136   \n",
            "_________________________________________________________________\n",
            "bidirectional_33 (Bidirectio (None, None, 256)         394240    \n",
            "_________________________________________________________________\n",
            "bidirectional_34 (Bidirectio (None, 128)               164352    \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 9,330,764\n",
            "Trainable params: 9,330,764\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZB3Tw4Qac99",
        "colab_type": "code",
        "outputId": "c11c57ec-4397-4ebc-a9ca-31c3a9741f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid), validation_steps=30)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 117s 4s/step - loss: 29.3381 - accuracy: 0.2325 - val_loss: 37.7600 - val_accuracy: 0.2803\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 117s 4s/step - loss: 44.0236 - accuracy: 0.2597 - val_loss: 53.9264 - val_accuracy: 0.0502\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 115s 4s/step - loss: 61.5403 - accuracy: 0.2031 - val_loss: 72.6553 - val_accuracy: 0.0502\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 116s 4s/step - loss: 73.8393 - accuracy: 0.2230 - val_loss: 87.6622 - val_accuracy: 0.0502\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 114s 4s/step - loss: 89.5089 - accuracy: 0.1749 - val_loss: 104.4210 - val_accuracy: 0.2803\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 116s 4s/step - loss: 107.6097 - accuracy: 0.2000 - val_loss: 122.9364 - val_accuracy: 0.0502\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 127s 4s/step - loss: 119.2959 - accuracy: 0.1770 - val_loss: 135.8963 - val_accuracy: 0.0251\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 125s 4s/step - loss: 125.9108 - accuracy: 0.1539 - val_loss: 141.1742 - val_accuracy: 0.2803\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 119s 4s/step - loss: 135.7522 - accuracy: 0.1853 - val_loss: 157.9946 - val_accuracy: 0.3598\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 118s 4s/step - loss: 150.7706 - accuracy: 0.2188 - val_loss: 177.1493 - val_accuracy: 0.0502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8bdea91c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEkNrUPqiI-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"/gdrive/My Drive/model_weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvUD1HPO_dsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8119599a-6d99-4883-e13c-b4a25b9c8103"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x=x_test, y=y_test)\n",
        "\n",
        "print('Test Loss: {}'.format(test_loss))\n",
        "print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 6s 607ms/step - loss: 166.5581 - accuracy: 0.0535\n",
            "Test Loss: 166.55809020996094\n",
            "Test Accuracy: 0.05351170524954796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwff-YLWqAW9",
        "colab_type": "code",
        "outputId": "2b440b5f-ec8f-473d-c4f3-9febe4481707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "y_pred = model.predict(x_test)\n",
        "print(np.shape(y_pred))\n",
        "\n",
        "print(test.emotion[0:2])\n",
        "print(y_pred[0:2])"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(299, 12)\n",
            "[[3513.4736 3515.8044 3515.8245 3515.4172 3221.7644 3155.619  3510.2332\n",
            "  3514.678  3508.7786 3200.6213 3420.8086 3200.8333]\n",
            " [3513.4626 3515.7898 3515.81   3515.4026 3221.7524 3155.6082 3510.2202\n",
            "  3514.6646 3508.765  3200.6094 3420.7961 3200.8225]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29kzs3iTwubN",
        "colab_type": "code",
        "outputId": "98d0eaf9-9dbc-434c-fddd-ecad5d14d3d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(pred[0:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "870     anger\n",
            "4097    anger\n",
            "Name: label, dtype: object\n",
            "[['anger: 0.017847503', 'anticipation: 0.0024762717', 'disgust: 0.0153170265', 'fear: 0.0039503183', 'joy: 0.11570063', 'love: 0.0025343532', 'neutral: 0.77372', 'optimism: 0.007678659', 'pessimism: 0.013150303', 'sadness: 0.000678027', 'surprise: 0.039906852', 'trust: 0.0070401705'], ['anger: 0.019174794', 'anticipation: 0.0024942586', 'disgust: 0.015852572', 'fear: 0.0039869486', 'joy: 0.116739854', 'love: 0.0024914858', 'neutral: 0.7706478', 'optimism: 0.0077296635', 'pessimism: 0.0133770695', 'sadness: 0.00069372635', 'surprise: 0.039548703', 'trust: 0.0072642933']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}